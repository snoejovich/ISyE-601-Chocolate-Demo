---
title: "Cleaned Image Rendering with Models"
output: html_notebook
---


```{r}
library(rvest) #webscraping package
library(jpeg) #convert scraped images to jpeg
library(xml2) #convert the xml from webpage into a list
library(dplyr)
library(EBImage)
library(magick)
library(janitor)
library(rvest)


#library(pdftools) # Reads pdf names into text strings
library(tm) # Text cleaning for large corpa similar to tidytext it can help with cleaning and tokenizing
library(quanteda) # Text cleaning for large corpa similar to tidytext tokenizing
library(tidytext) # For analysis of text in a tidy manner including sentiment data
library(textstem) # For stemming and lemmatizing text
library(gutenbergr) # Project Gutenberg books
library(wordcloud) # For world cloud
# 
library(lsa) # For latent semantic analysis
library(stm) # For structural topic modeling
library(uwot) # For umap dimensionality reduction
library(text2vec) # For cosine similarity -
library(kernlab) # For kernel-based cannonical correlation analysis
library(rPref) # For pareto frontier
library(DT) # For interactive data tables
library(textdata) # Database of lexicon and embeddings
# 
library(knitr)
library(ggrepel)
library(caret) # For predictive model fitting
library(tidyverse)
library(patchwork)
#biocLite("EBImage")
library (EBImage)


library(tidyverse)
library(kernlab)
library(dbscan)
library(clValid) # For selecting cluster method and number of clusters
library(factoextra) # for cluster fitting and visualization
library(uwot) # For UMAP dimensionality reduction 
library(patchwork) # For arranging multiple plots

set.seed(888) # To ensure consistent results from non-deterministic procedures
rm(list = ls()) # Removes all variables
```

#Data Collection and Manipulation

```{r}
simple= read_html("https://gailambrosius.com/explore-flavors/learn-about-the-flavors")
info_links = as_list(html_nodes(simple, ".popup")) #got all of the names of the chocolates

```



```{r Data reading and building of the dataframe}

attribs = list("width", "height","src", ".class", "alt", "srcset", "sizes")
#attribs[[1]]

d = c(1:length(info_links))
c_list = c()
width = c()
height =c()
src = c()
alt = c()
srcset = c()
sizes = c()
descr_list= c()

for(j in d){
    chocolate_img = info_links[j][[1]]$img
    chocolate_name = info_links[j][[1]]$div[[1]][1]
    # append(c_list, chocolate_name)
    descr_link = attr(info_links[j][[1]], "href")
    
  # identify = c(chocolate_name)
  for(i in attribs){
    # identify =c(identify, attr(chocolate_img, i))
    # if (i == "width"){
    #   width = c(width,attr(chocolate_img, i) )
    # }
    # else if (i == "height"){
    #   height = c(height,attr(chocolate_img, i) )
    # }
    if (i == "src"){
      src = c(src,attr(chocolate_img, i) )
    }
#     else if (i == "src"){
#       src = c(src,attr(chocolate_img, i) )
#     }
  }
# df = do.call(rbind.data.frame, identify
c_list =c(c_list, chocolate_name)
descr_list = c(descr_list, descr_link)

}
print(descr_list)
df <- data.frame ( 
                  name = c_list,
                  image_url = src,
                  d_list = descr_list
                  )

```



```{r html reading function}

reader <- function(url) {
  
  simple= read_html(url)

 x =  simple %>%
  html_nodes("p") %>%
  html_text()
 
 # print(typeof(x[1]))
 # print(typeof(x[2]))
 print(paste(x[1], x[2]), sep = " ")
  
}


```


```{r}
df[3,1] = "Cinnamon and Cayenne"
```


```{r Getting text using the reader function}
df$d_list <-as.character(df$d_list)
df["text"] = sapply(df$d_list, reader)
df$image_url <-as.character(df$image_url)


```

## Image Clustering from John

## Compute features for images
These features describe images such as the data in the Wisconsin Cancer data. These are morphological and texture properties of images

 
computeFeatures: Compute object features



#Collect Data

```{r}
#this gets all of the necessary jpegs
#for (i in 1:nrow(df))
df_test = data.frame()


for (i in 1:16)
{
  choc_name = df["name"][i,]
  print(choc_name)
  url = df["image_url"][i,]
  #print(url)
  download.file(url, paste(choc_name,".jpeg", sep=""), mode = "wb")
  file_name = paste(choc_name,".jpeg", sep="")
  print(file_name) #Blueberry, Caramel, Cinnamon
  
  #trycatch(Image, erro)

  Image <- readImage(file_name) #something is up with cinnamon
  
  
  
  
  
  Image3<-getFrame(Image,2) #changing the frame you grab does slightly change the results
  x = thresh(Image3, w=45, h=45, offset=0.05)
  x = opening(x, makeBrush(11, shape='diamond'))
  x = bwlabel(x)
  fts = computeFeatures.shape(x) #computing morphological and texture features of image objects
#the .shape compute features that


morph = fts %>%
  as_tibble() %>%
  mutate(across(.cols = everything(), list(mean = mean, sd = sd))) %>%
  mutate(count = n()) %>%
  select(7:19)
morph = head(morph, 1)
morph[is.na(morph)] = 0

morph$name = choc_name

#print(morph)

text <- computeFeatures.haralick(x, Image3)#the .shape compute features that 

text = as.data.frame(text)

haralickFeatures = text %>%
  as_tibble() %>%
  mutate(across(.cols = everything(), list(mean = mean, sd = sd))) %>%
  select(27:78) #h.asm.s1_mean should be the first one 
haralickFeatures  = head(haralickFeatures, 1) #remove the first row since it duplicates

haralickFeatures$name = choc_name

haralickFeatures[is.na(haralickFeatures)] = 0
#print(haralickFeatures)

final = merge(haralickFeatures, morph)

df_test = rbind(df_test, final)

#print(final)

#tada = rbind(final, df)
#rbind(df)
# row_select = df[i,]
# 
# okkk = merge(final, row_select)
# 
# #print(okkk)
# 
# 
# df_test = rbind(df_test, okkk)
# 
# print(df_test)
  
}

df_test


```

##Unsupverised Learning Set Up

```{r}
## Prepare data with removing NA and scaling
scaled.df = df_test %>% 
  drop_na() %>%  # Removes rows with missing data 
  select(-name) %>%
  scale() %>% as.data.frame() 




```


## Identify best method and number clusters with *internal* metrics
clValid makes it possible to fit a rnage of clusters (nClust) using a range of methods (clMethods) and evaluate with internal and stability metrics.

clValid identifies the best combination of method and number of clusters using internal metrics of connectivity, silhouette, and Dunn. Connectivity should be minimized and the others maximized.

```{r clValidInternal}

## Internal metrics
internal.cl = clValid(scaled.df, 
                  nClust = 2:10, 
                  clMethods = c("kmeans","pam", "agnes", "diana"),
                  maxitems = 1000, # specifies the number of cases considered
                  validation = "internal")

## View internal metrics   
summary(internal.cl)
plot(internal.cl)

```

## Identify best method and number clusters with *stability* metrics
Stability metrics estimate how consistent the clustering solution. Ideally you would get the same items belonging to the same clusters if the analysis is repeated.

```{r clValidStability}

## Stability  metrics
stability.cl = clValid(scaled.df, 
                nClust = 2:10, 
                clMethods = c("kmeans","pam", "agnes", "diana"),
                maxitems = 1700, # specifies the number of cases considered
                validation = "stability")

## View stability metrics
summary(stability.cl)
plot(stability.cl)

```


## Check optimal clustering using the gap method 
The gap metric measures the total intracluster variation relative to its expected value if there was no clustering.

```{r, cluster_estimation}

wine.agnes = eclust(scaled.df, 
                    FUNcluster = "kmeans", 
                    nboot = 200,
                    seed = 888)

# Silhouette plot
fviz_silhouette(wine.agnes)

```



## Fit and visualize best solution

```{r final_fit}

wine.agnes = eclust(scaled.df, 
       FUNcluster = "agnes", 
       k = 2 ,
       hc_metric = "euclidean", hc_method = "ward.D2", # Distance metric and aglomeration method
       seed = 888)

# Silhouette plot
fviz_silhouette(wine.agnes)

# Dendrogam plot
fviz_dend(wine.agnes) 

# Plot cluster membership in PCA space
fviz_cluster(wine.agnes)

```


## Estimate cluster membership with UMAP-transformed data
UMAP reduces the dimensionality of the data by combining the number of columns. It can create a low-dimensional representation where similar cases are near each other. 
```{r umapcluster}

## Apply umap to data
umap.df = umap(scaled.df, n_neighbors = 3, n_components = 2) %>% scale()
colnames(umap.df) = c("umap1", "umap2")
umap.df = as.data.frame(umap.df)

umap.plot = ggplot(umap.df, aes(umap1, umap2)) + 
  geom_point(size = .5) +
  labs(title = "UMAP-transformed data") +
  theme_bw() 
umap.plot

sample.scaled.wine.df = cbind(scaled.df, umap.df)

## More components capture more information
umap4.df = umap(scaled.df, n_neighbors = 3, n_components = 4) %>% scale()

## Cluster based on UMAP data
internal.cl = clValid(umap4.df, 
                  nClust = 2:12, 
                  clMethods = c("kmeans", "pam", "agnes", "diana"),
                  maxitems = 1700,
                  validation = "internal")

## View internal metrics   
summary(internal.cl)
plot(internal.cl)

## Cluster based on UMAP data
stability.cl = clValid(umap4.df, 
                  nClust = 2:12, 
                  clMethods = c("kmeans", "pam", "agnes", "diana"),
                  maxitems = 1700,
                  validation = "stability")

## View internal metrics   
summary(stability.cl)
plot(stability.cl)


## UMAP and kmeans
umap.wine.kmean = eclust(umap.df, 
       FUNcluster = "kmeans", 
       k = 8,
       seed = 888)
  

sample.scaled.wine.df = cbind(scaled.df, cluster = as.factor(umap.wine.kmean$cluster))

print(sample.scaled.wine.df)

# km_umap.plot =
#   ggplot(sample.scaled.wine.df, aes(umap1, umap2, colour = cluster)) +
#   geom_point(size = 1) +
#   labs(title = "Kmeans clustering based on UMAP transformed data", x = "", y = "") +
#   theme_bw() +
#   theme(legend.position = "none")
# 
# km_umap.plot

## Hierarchical density based clustering is very sensitive to the minimum number of points
sample.scaled.wine.df$hdb.cluster = hdbscan(as.matrix(umap4.df), minPts = 3)$cluster %>%    
  as.factor()

hdbscan.plot = 
  ggplot(sample.scaled.wine.df, aes(umap1, umap2, colour = hdb.cluster)) + 
  geom_point(size = 1) + 
  labs(title = "HDBscan clustering based on UMAP transformed data", x = "", y = "") +
  theme_bw() + 
  theme(legend.position = "none") 
hdbscan.plot

```

